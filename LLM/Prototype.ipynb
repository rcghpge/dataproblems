{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "440b1eef-6cf5-416d-b703-fbad9423f05a",
   "metadata": {},
   "source": [
    "# LLM Prototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "155750b5-7c31-4f55-9074-199ffeead3c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rc/version-llm\n"
     ]
    }
   ],
   "source": [
    "# Workflow prototype build\n",
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "92387fe3-087f-4948-908f-8db7ca018917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rc/version-llm\n"
     ]
    }
   ],
   "source": [
    "#!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e88f71-f7c7-4510-9e5b-6233cb104402",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "#os.chdir(\"../\")\n",
    "#subprocess.run([\"bash\", \"uvicorn\", \"main:app\", \"--reload\"])\n",
    "\n",
    "# Start uvicorn server \n",
    "process = subprocess.Popen([\"uvicorn\", \"main:app\", \"--reload\"])\n",
    "\n",
    "print(\"Server is running. To close the server down run -> process.terminate()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "200fed12-e15f-41b1-8447-478025cba654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cwd: /home/rc/version-llm\n",
      "Loading env from: /home/rc/version-llm/backend/.env\n",
      "GOOGLE_API_KEY is set.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load .env from backend\n",
    "env_path = Path(\"backend/.env\")\n",
    "print(f\"cwd: {os.getcwd()}\")\n",
    "print(f\"Loading env from: {env_path.resolve()}\")\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "# Check for API key presence only\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "if api_key:\n",
    "    print(\"GOOGLE_API_KEY is set.\")\n",
    "else:\n",
    "    print(\"GOOGLE_API_KEY is NOT set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b330b4c7-7464-4d5d-b174-f9127ee84adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cwd: /home/rc/version-llm\n",
      "Loading env from: /home/rc/version-llm/backend/.env\n",
      "GEMINI_API_KEY is set.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load .env from backend\n",
    "env_path = Path(\"backend/.env\")\n",
    "print(f\"cwd: {os.getcwd()}\")\n",
    "print(f\"Loading env from: {env_path.resolve()}\")\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "# Check for API key presence only\n",
    "api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "if api_key:\n",
    "    print(\"GEMINI_API_KEY is set.\")\n",
    "else:\n",
    "    print(\"GEMINI_API_KEY is NOT set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c4f7bc79-fd6c-4c51-9ad9-7349a98c4cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**In 5 words:**\n",
      "\n",
      "Learning from data to make predictions.\n",
      "\n",
      "**In one sentence:**\n",
      "\n",
      "It's teaching a computer to recognize patterns, so it can make decisions on its own.\n",
      "\n",
      "**With a simple analogy:**\n",
      "\n",
      "Instead of programming a computer with rules, you show it millions of examples (like pictures of cats), and it learns the rules for itself.\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "\n",
    "client = genai.Client(api_key=\"api key\")\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-pro\", contents=\"Explain how AI works in a few words\"\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5896d554-c90c-4e49-bf4b-d4525179a085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Terminate server\n",
    "process.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3ffd2f75-35e6-4c61-af53-5ddb59aceb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Web dev notes:\n",
    "\"\"\"\n",
    "The project requires backend and frontend web development. This is what is known as full stack development in software engineering. \n",
    "Shutting down processes in the local dev environment. Testing server and client-side UI (user interface).\n",
    "\"\"\"\n",
    "\n",
    "!lsof -i :8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0e90bded-5ae9-4295-979a-75ca596090fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kill processes by ID\n",
    "!kill -9 32707 32709 32709"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d67af09-3c4b-48af-ba0d-94f9fa97486f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Gemini CLI expects structured arguments.\n",
    "import subprocess\n",
    "import shlex\n",
    "\n",
    "prompt_text = \"are you there\"\n",
    "cmd = [\"gemini\", \"-p\", prompt_text]  # NOT: [\"gemini\", prompt_text]\n",
    "try:\n",
    "    output = subprocess.check_output(cmd, text=True)\n",
    "    print(output)\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"Gemini CLI error: {e}\")\n",
    "\n",
    "# Test to use Goggle/Gemini SDK directly in backend builds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268fa3e5-83c7-463b-84b2-77b72920a5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from bash to start/run server in productions\n",
    "gunicorn main:app -k uvicorn.workers.UvicornWorker --bind 0.0.0.0:8000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a95e96-f07e-4bdf-aa62-718e674a66a2",
   "metadata": {},
   "source": [
    "## frontend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fcf406-beb6-4e08-bb0e-724697141ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GH pages deploy\n",
    "const response = await fetch(\"http://localhost:8000/api/generate\", {\n",
    "  method: \"POST\",\n",
    "  headers: { \"Content-Type\": \"application/json\" },\n",
    "  body: JSON.stringify({ prompt: prompt, engine: useGemini ? \"cli\" : \"local\" })\n",
    "});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957f046d-ac5e-4c15-8bc8-f5ee7c200faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Set file paths\n",
    "sys.path.append(\"../\") \n",
    "\n",
    "# Set directories\n",
    "os.chdir(\"../\") \n",
    "\n",
    "# Bash scripting in Jupyter\n",
    "subprocess.run([\"bash\", \"your_script.sh\"])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b11191-3bfe-49e1-9365-10ccaacad9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# May implement another build method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5731aa-4bd9-4d29-896e-2dfea0448b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# end of prototype test builds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
