{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "933b17f8",
   "metadata": {},
   "source": [
    "# Tabular Feasibility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1678fd78-6907-4dd9-9d98-0f97d9c55101",
   "metadata": {},
   "source": [
    "### Version & Annum\n",
    "#### Project Link: https://github.com/rcghpge/dataproblems/tree/main/src/projects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904a84f9-ca98-4542-9dd0-e50c3c0a080f",
   "metadata": {},
   "source": [
    "**Project Summary:**\n",
    "This feasibility study covers two parallel tabular AI projects: Version and Annum.\n",
    "\n",
    "Version proposes a tabular NLP-based framework to establish a reproducible and ethical standard for data science using Python, EDA, a proposal of a novel method exploratory deep learning, and ML.\n",
    "\n",
    "Annum looks to extend this in development using a novel architecture with FreeBSD OS, Mojo, Apache technologies, and other frameworks to explore modular, secure ML systems for tabular data and data that require NLP methods.\n",
    "\n",
    "**Challenge Description:**\n",
    "Build iterative versions of 2 projects for tabular data and the NLP domain. Refine and prep for computer vision phase in builds and llm phase of project(s) requirements. For a shippable package for the Python stdlib. R&D what is feasibile with the time allotted per project build domain(s).\n",
    "\n",
    "**Datasets Considered:**\n",
    "\n",
    "MIMIC-IV: Clinical EHR data (MIT); utilized for supervised health prediction tasks\n",
    "\n",
    "MMLU-Pro: NLP-based benchmark for LLMs and reasoning\n",
    "\n",
    "HLE (Humanity’s Last Exam): A global academic benchmark for evaluating LLM generalization and subject-matter breadth\n",
    "\n",
    "Mathematics Dataset: A collection of mathematical question-answer pairs at school-level difficulty, designed to test and train neural models on mathematical problems for problem-solving.\n",
    "\n",
    "**Type of Machine Learning:**\n",
    "\n",
    "**Supervised Learning + Novel Architecture**\n",
    "\n",
    "This project explores binary classification tasks of Q&A pairs using supervised machine learning and deep learning. The modeling focus is on both binary and maybe multiclass classification depending on the dataset and task context + sandbox R&D.\n",
    "\n",
    "- **Version** The original goal(s) were focusing on binary classification utilizing the MIMIC-IV dataset, such as predicting patient mortality `1 = mortality`, `0 = mortality` or other predictive outcomes. Although the main goal is to integrate tabular and NLP modeling; For Version and in extension, Annum, a proposed novel method or not yet fully established method--exploratory deep learning (EDL) will be utilized for research purposes. The final build goal(s) are a protoype model for predictive outcomes though time constraints may not allow it. So the focus of these builds are the mathematical field, industry leading test data, and preparation for a shippable package in Python though this is TBD.\n",
    "\n",
    "- **Annum** emphasizes a novel architecture as well + novel approaches and methods for ML pipelines. While not model-centric, the goal here is build with other technologies currently not widely utilized in the field of data science.\n",
    "\n",
    "**R&D Goal and Notes:**  \n",
    "- Both models will be developed using a Scikit-Learn + TensorFlow/Keras framework and evaluated on benchmark QA datasets (MMLU-Pro, HLE, and the Google DeepMind math_dataset) to assess generalization and reasoning.\n",
    "\n",
    "- The MMLU-Pro and HLE datasets will be used for zero-shot multiclass benchmarking. Due to time constraints, MIMIC-IV will not be included in these builds, in line with PhysioNet and MIT Laboratory for Computational Physiology recommendations that derivative works be published on their platform.\n",
    "\n",
    "- Research sources include the Google DeepMind Mathematics Dataset, which will serve as the primary dataset for both training and testing these models. These are new models, independent from the originally proposed architecture.\n",
    "\n",
    "- The primary goal is to explore portability, reproducibility, and architectural flexibility of tabular and NLP-based ML/DL systems in scientific and potentially broader domains.\n",
    "\n",
    "- A formal literature review using the PRISMA method was considered to guide R&D on computer vision and general-purpose LLMs. However, due to scope and time constraints, the math_dataset will serve as the main baseline for these builds, a light reading of existing research, and will be central to both training and testing workflows.\n",
    "\n",
    "- In parallel, Annum will be developed using Hugging Face Transformers. Annum's focused on R&D test runs with pretrained models to evaluate transfer learning capabilities, with additional training and testing on the math_dataset to assess mathematical reasoning and generalization.\n",
    "\n",
    "**Responsible Data Science** — Privacy, governance, and explainability:\n",
    "While working with real-world data, important factors and considerations are taken into account such as data privacy, data governance, and explainable AI (XAI)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a390289",
   "metadata": {},
   "source": [
    "## Data Loading and Initial Look"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98633522-0aeb-4332-b2bb-5c7589a0c3b9",
   "metadata": {},
   "source": [
    "**- See `docs/tabular` notebooks for preliminary overview of data, benchmark data, and further details.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1820b27f",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aaf7d52-5e59-4bfa-a113-90f563a71406",
   "metadata": {},
   "source": [
    "### MMLU-Pro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a07afc5-1208-4b59-bf34-4b347a9efbd7",
   "metadata": {},
   "source": [
    "External link: [MMLU-Pro Data Visualization](https://rcghpge.github.io/dataproblems/mmlupro_overview.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebae7dcb-a870-4d4a-a2ee-aa896102021e",
   "metadata": {},
   "source": [
    "![Distribution of Disciplines for MMLU-Pro](https://cdn-uploads.huggingface.co/production/uploads/636a35eff8d9af4aea181608/M7mJcKstlVHo6p7P4Cu1j.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39450e48",
   "metadata": {},
   "source": [
    "## Data Cleaning and Preparation for Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138ec881-5e48-4a8c-8a72-2de78efc4d94",
   "metadata": {},
   "source": [
    "### math_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bdad31-429c-4af9-a479-f67cdfe6563b",
   "metadata": {},
   "source": [
    "<center><img src=\"../src/img/version-plot.png\" alt=\"mmlu-pro\" height=\"250\" width=\"500\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320f7aac-96f4-4af7-a97b-1f60fbf0362e",
   "metadata": {},
   "source": [
    "<center><img src=\"../src/img/version-plot3.png\" alt=\"mmlu-pro\" height=\"250\" width=\"500\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56365ca-c0bf-4044-ada0-b72891282513",
   "metadata": {},
   "source": [
    "MMLU-Pro + HLE datasets require EDA advanced methods. The baseline builds are with the `math_dataset`. These are for iterative prototyped \n",
    "baseline builds.\n",
    "\n",
    "- See notebooks in `docs/tabular` directory for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20932efa-cf16-4231-85d4-726730c6d91a",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc11586-8ac5-4b98-95ba-f8830a7cecc5",
   "metadata": {},
   "source": [
    "This is doable though not 100% complete from intials estimations. A shippable Python package is feasible but requires a lot of work. \n",
    "- See sandbox at `src/projects/version/sandbox` directory for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250b7fc7-b93c-4b94-86d5-3853825a10db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
