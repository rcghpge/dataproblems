{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7380fe21-e463-4cc8-b924-5b49ed03011a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Robert Cocker\n",
    "# Dr. Farbin\n",
    "# DATA-4380\n",
    "# Tabular Feasibility\n",
    "# 6/24/2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933b17f8",
   "metadata": {},
   "source": [
    "# Tabular Feasibility\n",
    "\n",
    "For Wednesday June 25 you should be well on your way to assess feasibility of your project. This notebook will be submitted Friday June 27. You can find example codes in [Kaggle Lecture](https://github.com/UTA-DataScience/DATA3402.Spring.2025/blob/main/Lectures/Lecture.19/Lecture.19.ipynb) from Data 3402. You can find the recordings of a walk-through in our class Team (`Data 4380- 2024/Lecture Recordings`), Lectures 8 and 10-12.\n",
    "\n",
    "\n",
    "## Define Project\n",
    "\n",
    "To establish the context of the feasibility study, write a short introduction, mostly summarizing info that was in your proposal:\n",
    "\n",
    "* Provide Project link.\n",
    "* Short paragraph describing the challenge. \n",
    "* Briefly describe the data.\n",
    "* What type of Machine Learning? Supervised Classification (binary or multiclass) or Regression? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1678fd78-6907-4dd9-9d98-0f97d9c55101",
   "metadata": {},
   "source": [
    "### Version & Annum\n",
    "#### Project Link: https://github.com/rcghpge/DATA4380.Summer.2025/tree/main/src/projects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904a84f9-ca98-4542-9dd0-e50c3c0a080f",
   "metadata": {},
   "source": [
    "üì¶ **Project Summary:**\n",
    "This feasibility study covers two parallel tabular AI projects: Version and Annum.\n",
    "\n",
    "Version proposes a tabular NLP-based framework to establish a reproducible and ethical standard for data science using Python, EDA, and ML.\n",
    "\n",
    "Annum extends this vision using a novel system architecture rooted in FreeBSD, Mojo, Apache technologies, and other frameworks to explore modular, secure ML systems for tabular data.\n",
    "\n",
    "üìà **Challenge Description:**\n",
    "Data science lacks a foundational and rigorously defined standard across disciplines. These projects aim to formalize tabular AI practices, benchmark emerging methods, and deploy interpretable, secure, and scalable systems ‚Äî Version through mainstream Pythonic ML workflows, and Annum via other novel methods.\n",
    "\n",
    "üìä **Datasets Used:**\n",
    "\n",
    "MIMIC-IV: Clinical EHR data (MIT); utilized for supervised health prediction tasks\n",
    "\n",
    "MMLU-Pro: NLP-based benchmark for LLMs and reasoning\n",
    "\n",
    "HLE (Humanity‚Äôs Last Exam): A global academic benchmark for evaluating LLM generalization and subject-matter breadth\n",
    "\n",
    "üñ•Ô∏è **Type of Machine Learning:**\n",
    "\n",
    "**Supervised Learning + Novel Architecture**\n",
    "\n",
    "This project explores classification tasks using supervised machine learning. The modeling focus is on both binary and multiclass classification depending on the dataset and task context + sandbox R&D.\n",
    "\n",
    "- **Version** focuses on binary classification utilizing the MIMIC-IV dataset, such as predicting patient mortality (`1 = deceased`, `0 = survived`). It integrates tabular NLP modeling and exploratory deep learning (EDL) for medical outcome prediction.\n",
    "\n",
    "- **Annum** emphasizes a novel architecture + system-level innovation for ML pipelines. While not model-centric, it supports multiclass classification experiments within a FreeBSD + Mojo-based backend environment.\n",
    "\n",
    "üî¨ **R&D Goal and Notes:**  \n",
    "Both models look to be trained using a Scikit-Learn + TensorFlow/Keras framework and evaluated on benchmark QA datasets (**MMLU-Pro** and **HLE**) to assess generalization and reasoning. These datasets are used for zero-shot multiclass benchmarking, while training is on project-curated data (e.g., MIMIC-IV). The goal is to explore the portability, reproducibility, and architectural flexibility of tabular NLP-based ML systems in scientific domains. PhysioNet via the Laboratory for Computational Physiology @ MIT recommend that any derivative works from MIMIC-IV be published on their platform. For research and development a formal literature review of the start of the art via the PRISMA method will be conducted with computer vision and general-purpose LLM's in mind.\n",
    "\n",
    "**Responsible Data Science** ‚Äî Privacy, Governance, and Explainability\n",
    "While working with real-world data, important factors and considerations are taken into account such as data privacy, data governance, and explainable AI (XAI)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a390289",
   "metadata": {},
   "source": [
    "## Data Loading and Initial Look\n",
    "\n",
    "First lets establish that the data is in good shape:\n",
    "\n",
    "* Load the data. \n",
    "* Count the number of rows (data points) and features.\n",
    "* Any missing values? \n",
    "* Make a table, where each row is a feature or collection of features:\n",
    "    * Is the feature categorical or numerical\n",
    "    * What values? \n",
    "        * e.g. for categorical: \"0,1,2\"\n",
    "        * e.g. for numerical specify the range\n",
    "    * How many missing values\n",
    "    * Do you see any outliers?\n",
    "        * Define outlier.\n",
    "    * If you have a lot of features, summarize (e.g. 100 categorical and 500 numerical features).\n",
    "* For classification is there class imbalance?\n",
    "* What is the target:\n",
    "    * Classification: how is the target encoded (e.g. 0 and 1)?\n",
    "    * Regression: what is the range?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98633522-0aeb-4332-b2bb-5c7589a0c3b9",
   "metadata": {},
   "source": [
    "**- See Feasiability-EDA.ipynb notebook for overview of benchmark data and further details.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1820b27f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "## Data Visualization\n",
    "\n",
    "Next perform your first visualizaion:\n",
    "\n",
    "* For classification: compare histogram every feature between the classes. Lots of examples of this in class.\n",
    "* For regression: \n",
    "    * Define 2 or more class based on value of the regression target.\n",
    "        * For example: if regression target is between 0 and 1:\n",
    "            * 0.0-0.25: Class 1\n",
    "            * 0.25-0.5: Class 2\n",
    "            * 0.5-0.75: Class 3\n",
    "            * 0.75-1.0: Class 4\n",
    "    * Compare histograms of the features between the classes.\n",
    "        \n",
    "* Note that for categorical features, often times the information in the histogram could be better presented in a table.    \n",
    "* Make comments on what features look most promising for ML task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aaf7d52-5e59-4bfa-a113-90f563a71406",
   "metadata": {},
   "source": [
    "### MMLU-Pro Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16255622-2862-4d2b-af63-2f3cbdb77cf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000\"\n",
       "            height=\"600\"\n",
       "            src=\"mmlupro_overview.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7efa61dbdd60>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import IFrame\n",
    "\n",
    "IFrame(\"mmlupro_overview.html\", width=1000, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39450e48",
   "metadata": {},
   "source": [
    "## Data Cleaning and Preperation for Machine Learning\n",
    "\n",
    "Based on what you find above, prepare the data for ML.\n",
    "\n",
    "* Perform any data cleaning. Be clear what are you doing, for what feature. \n",
    "* Determinine if rescaling is important for your Machine Learning model.\n",
    "    * If so select strategy for each feature.\n",
    "    * Apply rescaling.\n",
    "* Visualize the features before and after cleaning and rescaling.\n",
    "* One-hot encode your categorical features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56365ca-c0bf-4044-ada0-b72891282513",
   "metadata": {},
   "source": [
    "**HLE data requires advanced methods. MIMIC-IV data is needed. TBD.**\n",
    "\n",
    "*-See Feasiability-EDA.ipynb notebook for preliminary EDA and details.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20932efa-cf16-4231-85d4-726730c6d91a",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc11586-8ac5-4b98-95ba-f8830a7cecc5",
   "metadata": {},
   "source": [
    "Buildable. A straightforward method for NLP would be to plug in RAG into the architecture builds. Models can be built for versatility. Awaiting approval for data needed. Biomedical protocols for biomedical data is required as this pertains to the biomedical field + medicine and other domains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250b7fc7-b93c-4b94-86d5-3853825a10db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
